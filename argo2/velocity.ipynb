{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    elif split == 'test':\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "        \n",
    "    else:\n",
    "        print('\\\"split\\\" should be train, val, or test.')\n",
    "        inputs = None\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        \n",
    "        # centering\n",
    "        num_inputs, input_seq_len = self.inputs.shape[:2]\n",
    "        num_outputs, output_seq_len = self.outputs.shape[:2]\n",
    "        center_input = (\n",
    "            np.repeat(self.inputs[:, 0, :], input_seq_len, axis=0)\n",
    "            .reshape(num_inputs, input_seq_len, 2)\n",
    "        )\n",
    "        center_output = (\n",
    "            np.repeat(self.inputs[:, 0, :], output_seq_len, axis=0)\n",
    "            .reshape(num_outputs, output_seq_len, 2)\n",
    "        )\n",
    "        self.inputs -= center_input\n",
    "        self.outputs -= center_output\n",
    "        self.input_velocities = np.hstack((np.zeros((num_inputs, 1, 2)), np.diff(self.inputs, axis=1)))\n",
    "        self.output_velocities = np.hstack((np.zeros((num_outputs, 1, 2)), np.diff(self.outputs, axis=1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx], self.input_velocities[idx], self.output_velocities[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Creating velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b4bf83c8-ace4-4720-b8fd-18c2993a3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"austin\"\n",
    "train_dataset = ArgoverseDataset(city = city, split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5a24bd0b-ad83-43fa-b7c0-34e760516c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "austin0 = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "885eeba8-c403-47ea-8a6f-b9b725f984ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "austin0_input, austin0_output, austin0_input_velocities, austin0_output_velocities = austin0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224a1e1-33a2-45db-ba51-121887ed82f1",
   "metadata": {},
   "source": [
    "Note: the problem with the current version is that even if output velocity is correctly predicted, the first position of the output still needs to be accurately predicted in order for the cumulative sum to be the output positions. This should be an easier task than predicting the entire output sequence, however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfe7a8-0a42-480f-a910-4bd3a7f578a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e642286-9784-4de9-adc1-72100792ad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb3a89-4ecb-4fb3-b412-44524e2810c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda4ee8-8e90-4601-966b-560c637bd12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08620847-e857-4fed-8aaa-fd12570a4e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a2644-3b2c-4276-a4c5-2ba7b21d1b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f703d9d1-2243-4cc8-8f1b-94237e80190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(size=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "99b64669-35e6-4554-85c0-bbbadde50ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15971921, 0.3918624 ],\n",
       "       [0.44660739, 0.57008611],\n",
       "       [0.3212512 , 0.51697017],\n",
       "       [0.80102251, 0.52036852],\n",
       "       [0.11094208, 0.55893831]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fb7e3d5a-d86f-4fb9-961d-5dc7ce9abdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15971921, 0.3918624 ],\n",
       "       [0.44660739, 0.57008611],\n",
       "       [0.3212512 , 0.51697017],\n",
       "       [0.80102251, 0.52036852],\n",
       "       [0.11094208, 0.55893831]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((x[0, :], np.diff(x, axis=0))).cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d7977-de53-45e9-b334-e840bba10591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c3802-a23a-41ab-a481-93b95cbde8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0e426-fb02-4bbe-9b1a-d8911deb211f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7c554c00-5ca7-4947-8d55-4ddccd639b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ],\n",
       "       [ 0.28688818,  0.17822371],\n",
       "       [-0.12535619, -0.05311594],\n",
       "       [ 0.47977131,  0.00339835],\n",
       "       [-0.69008043,  0.0385698 ]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.zeros(2), np.diff(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f632a-357c-482b-8037-e3d999ad848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b27401-a7cb-4efe-bac7-bd47dd1fdc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
