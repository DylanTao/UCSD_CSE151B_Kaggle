{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07579624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056cee79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 20 17:33:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 460.67                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "|  0%   31C    P8     9W / 250W |   1436MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "Internal error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class Pred(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 120)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fa57f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pred, opt, train_dataset, train_loader, val_dataset, val_loader):\n",
    "    device = torch.device('cuda:0')\n",
    "    pred = pred.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(50):\n",
    "\n",
    "        total_loss = 0\n",
    "        for i_batch, sample_batch in enumerate(train_loader):\n",
    "            inp, out = sample_batch\n",
    "            out = out.to(device)\n",
    "            inp = inp.to(device)\n",
    "            preds = pred(inp)\n",
    "            loss = ((preds - out) ** 2).sum()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, out = sample_batch\n",
    "            out = out.to(device)\n",
    "            inp = inp.to(device)\n",
    "            preds = pred(inp)\n",
    "            #print(preds)\n",
    "            loss = ((preds - out) ** 2).sum()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        train_loss = np.log(total_loss / len(train_dataset))\n",
    "        val_loss = np.log(val_loss / len(val_dataset))\n",
    "\n",
    "        print('epoch {} train_loss: {} val_loss: {}'.format(epoch, train_loss, val_loss))\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(train_losses, color =\"red\", label = \"train_loss\")\n",
    "    plt.plot(val_losses, color =\"blue\", label = \"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "564cd63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: austin\n",
      "epoch 0 train_loss: 17.73970132543029 val_loss: 12.59256552048736\n",
      "epoch 1 train_loss: 12.015795204711466 val_loss: 11.82150257393229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_578/2316083738.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(pred, opt, train_dataset, train_loader, val_dataset, val_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "#train city models\n",
    "for city in cities:\n",
    "    print('city: ' + city)\n",
    "    batch_sz = 128  # batch size\n",
    "    train_dataset  = ArgoverseDataset(city = city, split = 'train')\n",
    "    train_loader = DataLoader(train_dataset,batch_size=batch_sz)\n",
    "    val_dataset = ArgoverseDataset(city = city, split = 'val')\n",
    "    val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "    \n",
    "    pred = Pred()\n",
    "    opt = optim.Adam(pred.parameters(), lr=2e-4)\n",
    "    train(pred, opt, train_dataset, train_loader, val_dataset, val_loader)\n",
    "    pickle.dump(pred, open('models/ta_model_baseline_' + city + '_large', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458fbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cols = np.array(['v' + str(i) for i in range(120)])\n",
    "all_preds = []\n",
    "for city in cities:\n",
    "    load_pred = pickle.load(open('models/ta_model_baseline_' + city + '_large', 'rb'))\n",
    "    test_dataset = get_city_trajectories(city = city, split = 'test')\n",
    "    device = torch.device('cuda:0')\n",
    "    load_pred = load_pred.to(device)\n",
    "    preds = load_pred(torch.from_numpy(test_dataset[0]).to(device))\n",
    "    preds_reshaped = preds.reshape(preds.size()[0], 120)\n",
    "    preds_numpy = preds_reshaped.cpu().detach().numpy()\n",
    "    ids = np.array([str(i) + '_' + city for i in range(len(preds_numpy))])\n",
    "    predictions = pd.DataFrame(preds_numpy, columns=cols)\n",
    "    predictions.insert(0, 'ID', ids)\n",
    "    all_preds.append(predictions)\n",
    "    \n",
    "all_predictions = pd.concat(all_preds, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0dcf133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_austin</td>\n",
       "      <td>-31.452484</td>\n",
       "      <td>-562.548340</td>\n",
       "      <td>-33.952343</td>\n",
       "      <td>-565.756409</td>\n",
       "      <td>-32.007393</td>\n",
       "      <td>-564.075317</td>\n",
       "      <td>-30.762920</td>\n",
       "      <td>-563.210083</td>\n",
       "      <td>-31.028749</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.905733</td>\n",
       "      <td>-564.923950</td>\n",
       "      <td>-32.423668</td>\n",
       "      <td>-565.540039</td>\n",
       "      <td>-32.022629</td>\n",
       "      <td>-564.601624</td>\n",
       "      <td>-32.312786</td>\n",
       "      <td>-565.114441</td>\n",
       "      <td>-35.172150</td>\n",
       "      <td>-567.413391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_austin</td>\n",
       "      <td>-351.348969</td>\n",
       "      <td>-0.119122</td>\n",
       "      <td>-350.579590</td>\n",
       "      <td>0.138293</td>\n",
       "      <td>-349.517548</td>\n",
       "      <td>0.117330</td>\n",
       "      <td>-351.175507</td>\n",
       "      <td>-2.667399</td>\n",
       "      <td>-348.796692</td>\n",
       "      <td>...</td>\n",
       "      <td>-351.217377</td>\n",
       "      <td>-4.216088</td>\n",
       "      <td>-349.444855</td>\n",
       "      <td>1.408106</td>\n",
       "      <td>-347.734467</td>\n",
       "      <td>0.657192</td>\n",
       "      <td>-353.903961</td>\n",
       "      <td>-2.523358</td>\n",
       "      <td>-352.531555</td>\n",
       "      <td>-3.875669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_austin</td>\n",
       "      <td>52.536083</td>\n",
       "      <td>-247.152374</td>\n",
       "      <td>52.810318</td>\n",
       "      <td>-246.935181</td>\n",
       "      <td>52.799950</td>\n",
       "      <td>-247.529129</td>\n",
       "      <td>52.189980</td>\n",
       "      <td>-247.396378</td>\n",
       "      <td>52.836784</td>\n",
       "      <td>...</td>\n",
       "      <td>53.448818</td>\n",
       "      <td>-247.667999</td>\n",
       "      <td>53.442268</td>\n",
       "      <td>-247.301743</td>\n",
       "      <td>52.962234</td>\n",
       "      <td>-247.433365</td>\n",
       "      <td>53.182888</td>\n",
       "      <td>-247.676529</td>\n",
       "      <td>53.037708</td>\n",
       "      <td>-247.476486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_austin</td>\n",
       "      <td>-106.558907</td>\n",
       "      <td>1803.800537</td>\n",
       "      <td>-105.225006</td>\n",
       "      <td>1802.591431</td>\n",
       "      <td>-104.679924</td>\n",
       "      <td>1800.107422</td>\n",
       "      <td>-106.711349</td>\n",
       "      <td>1798.814697</td>\n",
       "      <td>-106.220612</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.779205</td>\n",
       "      <td>1801.653442</td>\n",
       "      <td>-103.487602</td>\n",
       "      <td>1800.609985</td>\n",
       "      <td>-102.373840</td>\n",
       "      <td>1803.712036</td>\n",
       "      <td>-102.916985</td>\n",
       "      <td>1799.536621</td>\n",
       "      <td>-102.170425</td>\n",
       "      <td>1802.438843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_austin</td>\n",
       "      <td>1230.415649</td>\n",
       "      <td>-646.340393</td>\n",
       "      <td>1228.973511</td>\n",
       "      <td>-644.798462</td>\n",
       "      <td>1229.457275</td>\n",
       "      <td>-643.078735</td>\n",
       "      <td>1231.996826</td>\n",
       "      <td>-644.133118</td>\n",
       "      <td>1231.857666</td>\n",
       "      <td>...</td>\n",
       "      <td>1231.125122</td>\n",
       "      <td>-641.399292</td>\n",
       "      <td>1232.445557</td>\n",
       "      <td>-644.789551</td>\n",
       "      <td>1230.611938</td>\n",
       "      <td>-642.621582</td>\n",
       "      <td>1231.720337</td>\n",
       "      <td>-645.117065</td>\n",
       "      <td>1231.885620</td>\n",
       "      <td>-640.346008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29838</th>\n",
       "      <td>1681_palo-alto</td>\n",
       "      <td>-1385.287231</td>\n",
       "      <td>-460.426483</td>\n",
       "      <td>-1380.776733</td>\n",
       "      <td>-461.190033</td>\n",
       "      <td>-1380.695679</td>\n",
       "      <td>-462.279510</td>\n",
       "      <td>-1384.988525</td>\n",
       "      <td>-461.701294</td>\n",
       "      <td>-1383.289429</td>\n",
       "      <td>...</td>\n",
       "      <td>-1368.622192</td>\n",
       "      <td>-469.239227</td>\n",
       "      <td>-1379.109741</td>\n",
       "      <td>-455.256287</td>\n",
       "      <td>-1376.202026</td>\n",
       "      <td>-466.640106</td>\n",
       "      <td>-1363.880127</td>\n",
       "      <td>-459.745361</td>\n",
       "      <td>-1375.023804</td>\n",
       "      <td>-463.403198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29839</th>\n",
       "      <td>1682_palo-alto</td>\n",
       "      <td>128.678925</td>\n",
       "      <td>-37.629963</td>\n",
       "      <td>129.935883</td>\n",
       "      <td>-38.154217</td>\n",
       "      <td>129.317322</td>\n",
       "      <td>-37.539192</td>\n",
       "      <td>128.578171</td>\n",
       "      <td>-37.556068</td>\n",
       "      <td>128.766876</td>\n",
       "      <td>...</td>\n",
       "      <td>129.638794</td>\n",
       "      <td>-37.775154</td>\n",
       "      <td>130.258606</td>\n",
       "      <td>-35.779835</td>\n",
       "      <td>128.943008</td>\n",
       "      <td>-36.716232</td>\n",
       "      <td>129.099106</td>\n",
       "      <td>-36.260242</td>\n",
       "      <td>129.076157</td>\n",
       "      <td>-37.493565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29840</th>\n",
       "      <td>1683_palo-alto</td>\n",
       "      <td>-1450.032471</td>\n",
       "      <td>2170.785889</td>\n",
       "      <td>-1451.728516</td>\n",
       "      <td>2174.138672</td>\n",
       "      <td>-1447.593018</td>\n",
       "      <td>2174.030518</td>\n",
       "      <td>-1450.204956</td>\n",
       "      <td>2171.910400</td>\n",
       "      <td>-1451.995361</td>\n",
       "      <td>...</td>\n",
       "      <td>-1444.619385</td>\n",
       "      <td>2177.399170</td>\n",
       "      <td>-1445.512207</td>\n",
       "      <td>2177.559814</td>\n",
       "      <td>-1445.637939</td>\n",
       "      <td>2177.074951</td>\n",
       "      <td>-1447.102295</td>\n",
       "      <td>2174.739746</td>\n",
       "      <td>-1446.107178</td>\n",
       "      <td>2176.353760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>1684_palo-alto</td>\n",
       "      <td>1048.192139</td>\n",
       "      <td>1382.367310</td>\n",
       "      <td>1046.368164</td>\n",
       "      <td>1398.683350</td>\n",
       "      <td>1048.355347</td>\n",
       "      <td>1384.482910</td>\n",
       "      <td>1051.488770</td>\n",
       "      <td>1388.268311</td>\n",
       "      <td>1055.826416</td>\n",
       "      <td>...</td>\n",
       "      <td>1044.473389</td>\n",
       "      <td>1392.719727</td>\n",
       "      <td>1047.746948</td>\n",
       "      <td>1390.432129</td>\n",
       "      <td>1051.738647</td>\n",
       "      <td>1399.739868</td>\n",
       "      <td>1042.208130</td>\n",
       "      <td>1396.866577</td>\n",
       "      <td>1051.914917</td>\n",
       "      <td>1390.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>1685_palo-alto</td>\n",
       "      <td>-67.455780</td>\n",
       "      <td>443.354065</td>\n",
       "      <td>-67.213112</td>\n",
       "      <td>443.221497</td>\n",
       "      <td>-67.405052</td>\n",
       "      <td>441.765900</td>\n",
       "      <td>-67.236221</td>\n",
       "      <td>442.978241</td>\n",
       "      <td>-64.175888</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.333839</td>\n",
       "      <td>445.994415</td>\n",
       "      <td>-64.983643</td>\n",
       "      <td>442.110321</td>\n",
       "      <td>-64.848579</td>\n",
       "      <td>444.341888</td>\n",
       "      <td>-65.824318</td>\n",
       "      <td>444.190491</td>\n",
       "      <td>-64.490982</td>\n",
       "      <td>444.711212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29843 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID           v0           v1           v2           v3  \\\n",
       "0            0_austin   -31.452484  -562.548340   -33.952343  -565.756409   \n",
       "1            1_austin  -351.348969    -0.119122  -350.579590     0.138293   \n",
       "2            2_austin    52.536083  -247.152374    52.810318  -246.935181   \n",
       "3            3_austin  -106.558907  1803.800537  -105.225006  1802.591431   \n",
       "4            4_austin  1230.415649  -646.340393  1228.973511  -644.798462   \n",
       "...               ...          ...          ...          ...          ...   \n",
       "29838  1681_palo-alto -1385.287231  -460.426483 -1380.776733  -461.190033   \n",
       "29839  1682_palo-alto   128.678925   -37.629963   129.935883   -38.154217   \n",
       "29840  1683_palo-alto -1450.032471  2170.785889 -1451.728516  2174.138672   \n",
       "29841  1684_palo-alto  1048.192139  1382.367310  1046.368164  1398.683350   \n",
       "29842  1685_palo-alto   -67.455780   443.354065   -67.213112   443.221497   \n",
       "\n",
       "                v4           v5           v6           v7           v8  ...  \\\n",
       "0       -32.007393  -564.075317   -30.762920  -563.210083   -31.028749  ...   \n",
       "1      -349.517548     0.117330  -351.175507    -2.667399  -348.796692  ...   \n",
       "2        52.799950  -247.529129    52.189980  -247.396378    52.836784  ...   \n",
       "3      -104.679924  1800.107422  -106.711349  1798.814697  -106.220612  ...   \n",
       "4      1229.457275  -643.078735  1231.996826  -644.133118  1231.857666  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "29838 -1380.695679  -462.279510 -1384.988525  -461.701294 -1383.289429  ...   \n",
       "29839   129.317322   -37.539192   128.578171   -37.556068   128.766876  ...   \n",
       "29840 -1447.593018  2174.030518 -1450.204956  2171.910400 -1451.995361  ...   \n",
       "29841  1048.355347  1384.482910  1051.488770  1388.268311  1055.826416  ...   \n",
       "29842   -67.405052   441.765900   -67.236221   442.978241   -64.175888  ...   \n",
       "\n",
       "              v110         v111         v112         v113         v114  \\\n",
       "0       -31.905733  -564.923950   -32.423668  -565.540039   -32.022629   \n",
       "1      -351.217377    -4.216088  -349.444855     1.408106  -347.734467   \n",
       "2        53.448818  -247.667999    53.442268  -247.301743    52.962234   \n",
       "3       -98.779205  1801.653442  -103.487602  1800.609985  -102.373840   \n",
       "4      1231.125122  -641.399292  1232.445557  -644.789551  1230.611938   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29838 -1368.622192  -469.239227 -1379.109741  -455.256287 -1376.202026   \n",
       "29839   129.638794   -37.775154   130.258606   -35.779835   128.943008   \n",
       "29840 -1444.619385  2177.399170 -1445.512207  2177.559814 -1445.637939   \n",
       "29841  1044.473389  1392.719727  1047.746948  1390.432129  1051.738647   \n",
       "29842   -65.333839   445.994415   -64.983643   442.110321   -64.848579   \n",
       "\n",
       "              v115         v116         v117         v118         v119  \n",
       "0      -564.601624   -32.312786  -565.114441   -35.172150  -567.413391  \n",
       "1         0.657192  -353.903961    -2.523358  -352.531555    -3.875669  \n",
       "2      -247.433365    53.182888  -247.676529    53.037708  -247.476486  \n",
       "3      1803.712036  -102.916985  1799.536621  -102.170425  1802.438843  \n",
       "4      -642.621582  1231.720337  -645.117065  1231.885620  -640.346008  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "29838  -466.640106 -1363.880127  -459.745361 -1375.023804  -463.403198  \n",
       "29839   -36.716232   129.099106   -36.260242   129.076157   -37.493565  \n",
       "29840  2177.074951 -1447.102295  2174.739746 -1446.107178  2176.353760  \n",
       "29841  1399.739868  1042.208130  1396.866577  1051.914917  1390.431641  \n",
       "29842   444.341888   -65.824318   444.190491   -64.490982   444.711212  \n",
       "\n",
       "[29843 rows x 121 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0731417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
