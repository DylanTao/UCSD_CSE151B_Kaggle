{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498e98a2-a15a-4be3-842c-25ed40af9e65",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f010662-209a-42ad-aa09-91a6c45e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b6af88b-26f7-4373-9bb8-cd0990d9d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a277321d-a237-4ee9-a1fe-38364e46038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc7736-a560-49c2-bb67-ca94d797d47f",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59577b66-7d8c-4033-a47a-4a43a4fa4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"../../argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    outputs = None\n",
    "    \n",
    "    if split == \"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    elif split == 'test':\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "        \n",
    "    else:\n",
    "        print('\\\"split\\\" should be train, val, or test.')\n",
    "        inputs = None\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        \n",
    "        # centering\n",
    "        num_inputs, input_seq_len = self.inputs.shape[:2]\n",
    "        num_outputs, output_seq_len = self.outputs.shape[:2]\n",
    "        center_input = (\n",
    "            np.repeat(self.inputs[:, 0, :], input_seq_len, axis=0)\n",
    "            .reshape(num_inputs, input_seq_len, 2)\n",
    "        )\n",
    "        center_output = (\n",
    "            np.repeat(self.inputs[:, 0, :], output_seq_len, axis=0)\n",
    "            .reshape(num_outputs, output_seq_len, 2)\n",
    "        )\n",
    "        self.inputs -= center_input\n",
    "        self.outputs -= center_output\n",
    "        self.inputs = torch.Tensor(self.inputs)\n",
    "        self.outputs = torch.Tensor(self.outputs)\n",
    "        # self.inputs = self.inputs.reshape(num_inputs, input_seq_len * 2)\n",
    "        # self.outputs = self.outputs.reshape(num_outputs, output_seq_len * 2)\n",
    "        \n",
    "        # build velocities\n",
    "        # self.input_velocities = np.hstack((np.zeros((num_inputs, 1, 2)), np.diff(self.inputs, axis=1)))\n",
    "        # self.output_velocities = np.hstack((np.zeros((num_outputs, 1, 2)), np.diff(self.outputs, axis=1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (\n",
    "            self.inputs[idx], \n",
    "            self.outputs[idx]# , \n",
    "            # self.input_velocities[idx], \n",
    "            # self.output_velocities[idx]\n",
    "        )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f53757ef-2ef5-4ed5-90fa-8a510cd36648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArgoverseDataset('austin', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ed09057-d9a7-44cc-adf7-d378d8d9650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4bbd94c7-1e62-4261-b2d0-bfa6190a3769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 34432, 2]), torch.Size([60, 34432, 2]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_dataset.inputs.transpose(1,0)\n",
    "y_train = train_dataset.outputs.transpose(1,0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2f9365a-6a92-448d-9ba0-6cbf0b2862e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 34432, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.transpose(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03a7e25b-98a8-4ac1-91d1-9db4154c4237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 50/50 [1:08:40<00:00, 82.41s/it, loss=1415.490]\n"
     ]
    }
   ],
   "source": [
    "model = lstm_encoder_decoder.lstm_seq2seq(\n",
    "    input_size = 2, \n",
    "    hidden_size = 15\n",
    ")\n",
    "loss = model.train_model(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    n_epochs = 50, \n",
    "    target_len = 60, \n",
    "    batch_size = 5, \n",
    "    training_prediction = 'mixed_teacher_forcing', \n",
    "    teacher_forcing_ratio = 0.6, \n",
    "    learning_rate = 0.01, \n",
    "    dynamic_tf = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80e53596-0658-43b5-8581-7a3960ab5e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 8609, 2]), torch.Size([60, 8609, 2]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = ArgoverseDataset('austin', 'val')\n",
    "X_val = val_dataset.inputs.transpose(1,0)\n",
    "y_val = val_dataset.outputs.transpose(1,0)\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bbe070bb-5b8a-49f2-82f0-82c636dd7522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495.8628164528739"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "for n in range(X_val.shape[1]):\n",
    "    mse += ((model.predict(X_val[:, n, :], 60) - y_val[:, n, :].numpy()) ** 2).sum()\n",
    "np.sqrt(mse / X_val.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94010ba5-8837-4bee-95c2-a71f205e59cc",
   "metadata": {},
   "source": [
    "### Altering hyperparameters (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a5937913-b7de-4787-8276-7f8f631cd206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 50/50 [10:29<00:00, 12.59s/it, loss=1538.736]\n"
     ]
    }
   ],
   "source": [
    "model2 = lstm_encoder_decoder.lstm_seq2seq(\n",
    "    input_size = 2, \n",
    "    hidden_size = 25\n",
    ")\n",
    "loss = model2.train_model(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    n_epochs = 50, \n",
    "    target_len = 60, \n",
    "    batch_size = 500, \n",
    "    training_prediction = 'mixed_teacher_forcing', \n",
    "    teacher_forcing_ratio = 0.6, \n",
    "    learning_rate = 0.0001, \n",
    "    dynamic_tf = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65f75e8a-1727-4966-a850-08d51e5d343c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436.2561363955811"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "for n in range(X_val.shape[1]):\n",
    "    mse += ((model2.predict(X_val[:, n, :], 60) - y_val[:, n, :].numpy()) ** 2).sum()\n",
    "np.sqrt(mse / X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e8a3acfe-2379-4beb-bacf-e80e9b586ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 250/250 [1:01:36<00:00, 14.79s/it, loss=442.136]\n"
     ]
    }
   ],
   "source": [
    "loss = model2.train_model(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    n_epochs = 250, \n",
    "    target_len = 60, \n",
    "    batch_size = 500, \n",
    "    training_prediction = 'mixed_teacher_forcing', \n",
    "    teacher_forcing_ratio = 0.6, \n",
    "    learning_rate = 0.0001, \n",
    "    dynamic_tf = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "220cb829-a8c3-4e30-be4b-bea080afd61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251.11387759824171"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "for n in range(X_val.shape[1]):\n",
    "    mse += ((model2.predict(X_val[:, n, :], 60) - y_val[:, n, :].numpy()) ** 2).sum()\n",
    "np.sqrt(mse / X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "82f2b33d-f21f-41e6-a1e6-8b9338a19d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.92513315444955"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_paloalto = ArgoverseDataset('palo-alto', 'train')\n",
    "X_train_paloalto = train_dataset_paloalto.inputs.transpose(1,0)\n",
    "y_train_paloalto = train_dataset_paloalto.outputs.transpose(1,0)\n",
    "\n",
    "mse = 0\n",
    "for n in range(X_train_paloalto.shape[1]):\n",
    "    mse += ((model2.predict(X_train_paloalto[:, n, :], 60) - y_train_paloalto[:, n, :].numpy()) ** 2).sum()\n",
    "np.sqrt(mse / X_train_paloalto.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f46eb285-8680-4d38-99b5-04c25d88fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, 'model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973fcc7-76e6-4e33-9079-9dcb3eb0e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want: `np.concatenate(output_position[0, :], output velocity[:, :]))` as output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
