{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498e98a2-a15a-4be3-842c-25ed40af9e65",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f010662-209a-42ad-aa09-91a6c45e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6af88b-26f7-4373-9bb8-cd0990d9d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_encoder_decoder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a277321d-a237-4ee9-a1fe-38364e46038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc7736-a560-49c2-bb67-ca94d797d47f",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59577b66-7d8c-4033-a47a-4a43a4fa4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"../../argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    outputs = None\n",
    "    \n",
    "    if split == \"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    elif split == 'test':\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "        \n",
    "    else:\n",
    "        print('\\\"split\\\" should be train, val, or test.')\n",
    "        inputs = None\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.split = split\n",
    "        self.input_positions, self.output_positions = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        \n",
    "        self.input_positions = torch.Tensor(self.input_positions)\n",
    "        num_inputs, input_seq_len = self.input_positions.shape[:2]\n",
    "        self.center_input = (\n",
    "            np.repeat(self.input_positions[:, 0, :], input_seq_len, axis=0)\n",
    "            .reshape(num_inputs, input_seq_len, 2)\n",
    "        )\n",
    "        self.center = (\n",
    "            np.repeat(self.input_positions[:, 0, :], 60, axis=0)\n",
    "            .reshape(num_inputs, 120)\n",
    "        )\n",
    "        \n",
    "        self.input_positions_centered = torch.Tensor(self.input_positions - self.center_input)\n",
    "        self.input_velocities = torch.Tensor(np.diff(self.input_positions, axis=1))\n",
    "        \n",
    "        self.nn_pos_inputs = self.input_positions_centered\n",
    "        self.nn_velo_inputs = self.input_velocities\n",
    "        \n",
    "        if split != 'test': \n",
    "            self.output_positions = torch.Tensor(self.output_positions)\n",
    "            num_outputs, output_seq_len = self.output_positions.shape[:2]\n",
    "            center_output = (\n",
    "                np.repeat(self.input_positions[:, 0, :], output_seq_len, axis=0)\n",
    "                .reshape(num_outputs, output_seq_len, 2)\n",
    "            )\n",
    "            self.output_positions_centered = torch.Tensor(self.output_positions - center_output)\n",
    "            self.output_velocities = torch.Tensor(np.diff(self.output_positions, axis=1))\n",
    "                    \n",
    "            self.nn_pos_outputs = self.output_positions_centered[:, 0, :].unsqueeze(1)\n",
    "            self.nn_velo_outputs = self.output_velocities\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nn_pos_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split != 'test':\n",
    "            data = (\n",
    "                self.nn_pos_inputs[idx], \n",
    "                self.nn_pos_outputs[idx], \n",
    "                self.nn_velo_inputs[idx], \n",
    "                self.nn_velo_outputs[idx],\n",
    "                self.input_positions[idx],\n",
    "                self.output_positions[idx],\n",
    "                self.input_positions_centered[idx],\n",
    "                self.output_positions_centered[idx]\n",
    "            )\n",
    "        else:\n",
    "            data = data = (\n",
    "                self.nn_pos_inputs[idx], \n",
    "                self.nn_velo_inputs[idx], \n",
    "                self.center[idx]\n",
    "            )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b93b7da-fb63-42c8-87bf-016a3bcc07c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 27 23:04:19 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 460.67                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 107...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8     5W / 180W |   7861MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "Internal error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4e942a-7c3d-4ebe-9766-ab5b44f1987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ArgoverseDataset('austin', 'train')\n",
    "# val_dataset = ArgoverseDataset('austin', 'train')\n",
    "# test_dataset = ArgoverseDataset('austin', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a9c0d9-c5d0-49bd-b4f6-e527a2f42a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in train_dataset.__getitem__(0):\n",
    "#     print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebe6736-a9f8-424e-a7b0-c059f8cfe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that tells how long training takes\n",
    "def train_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b1bd79-d89b-4c18-8c6b-d4c797a8d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training austin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_ALLOC_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/UCSD_CSE151B_Kaggle/argo2/seq2seq_lstm/lstm_encoder_decoder2.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, input_tensor_train, target_tensor_train, input_tensor_val, target_tensor_val, n_epochs, target_len, batch_size, training_prediction, teacher_forcing_ratio, learning_rate, dynamic_tf, early_stop_criteria, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# encoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;31m# decoder with teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_ALLOC_FAILED"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train one model for each city\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for city in cities:\n",
    "    print('Training ' + str(city))\n",
    "    train_dataset = ArgoverseDataset(city, 'train')\n",
    "    val_dataset = ArgoverseDataset(city, 'val')\n",
    "    \n",
    "    X_train_nn_pos = train_dataset.nn_pos_inputs.to(device)\n",
    "    y_train_nn_pos = train_dataset.nn_pos_outputs.to(device)\n",
    "    X_train_nn_velo = train_dataset.nn_velo_inputs.to(device)\n",
    "    y_train_nn_velo = train_dataset.nn_velo_outputs.to(device)\n",
    "    X_train = train_dataset.input_positions.to(device)\n",
    "    y_train = train_dataset.output_positions.to(device)\n",
    "    \n",
    "    X_val_nn_pos = val_dataset.nn_pos_inputs.to(device)\n",
    "    y_val_nn_pos = val_dataset.nn_pos_outputs.to(device)\n",
    "    X_val_nn_velo = val_dataset.nn_velo_inputs.to(device)\n",
    "    y_val_nn_velo = val_dataset.nn_velo_outputs.to(device)\n",
    "    X_val = val_dataset.input_positions.to(device)\n",
    "    y_val = val_dataset.output_positions.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    nn_pos = lstm_encoder_decoder2.lstm_seq2seq(\n",
    "    input_size = 2, \n",
    "    hidden_size = 64,\n",
    "    num_layers = 2,\n",
    "    dropout = 0.3\n",
    "    )\n",
    "    \n",
    "    nn_pos.to(device)\n",
    "    \n",
    "    val_losses_pos, valid_losses_pos = lstm_encoder_decoder2.train_model(\n",
    "        nn_pos,\n",
    "        X_train_nn_pos, \n",
    "        y_train_nn_pos, \n",
    "        X_val_nn_pos, \n",
    "        y_val_nn_pos, \n",
    "        n_epochs = 200, \n",
    "        target_len = 1, \n",
    "        batch_size = 128, \n",
    "        training_prediction = 'mixed_teacher_forcing', \n",
    "        teacher_forcing_ratio = 0.6, \n",
    "        learning_rate = 0.001, \n",
    "        dynamic_tf = False,\n",
    "        early_stop_criteria = 20,\n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Loss for \" + city + \"on initial position\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(train_losses_pos, color =\"red\", label = \"train_loss\")\n",
    "    plt.plot(valid_losses_pos, color =\"blue\", label = \"valid_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(loss1)\n",
    "    \n",
    "    nn_velo = lstm_encoder_decoder2.lstm_seq2seq(\n",
    "        input_size = 2, \n",
    "        hidden_size = 256,\n",
    "        num_layers = 2,\n",
    "        dropout = 0.3\n",
    "    )\n",
    "    \n",
    "    nn_velo.to(device)\n",
    "    \n",
    "    train_losses_velo, valid_losses_velo = lstm_encoder_decoder2.train_model(\n",
    "        nn_velo,\n",
    "        X_train_nn_velo, \n",
    "        y_train_nn_velo, \n",
    "        X_val_nn_velo, \n",
    "        y_val_nn_velo, \n",
    "        n_epoch = 300,\n",
    "        target_len = 59, \n",
    "        batch_size = 100, \n",
    "        training_prediction = 'mixed_teacher_forcing', \n",
    "        teacher_forcing_ratio = 0.6, \n",
    "        learning_rate = 0.0001, \n",
    "        dynamic_tf = False,\n",
    "        early_stop_criteria = 20,\n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Loss for \" + city + \"on velocity\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(train_losses_velo, color =\"red\", label = \"train_loss\")\n",
    "    plt.plot(valid_losses_velo, color =\"blue\", label = \"valid_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    train_mins, train_secs = train_time(start_time, end_time)\n",
    "    print(f'Total training time is: {train_mins}m {train_secs}s'+ ' for ' + city)\n",
    "    \n",
    "    \n",
    "    \n",
    "    nn_pos.eval()\n",
    "    nn_velo.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    for n in range(val_dataset.__len__()):\n",
    "        nn_pos_nth_input, nn_pos_nth_output, nn_velo_nth_input, nn_velo_nth_output, _, _, _, nth_output_centered = val_dataset.__getitem__(n)\n",
    "        init_pos = torch.Tensor(lstm_encoder_decoder2.predict(nn_pos, nn_pos_nth_input, 1))\n",
    "        deltas = torch.Tensor(lstm_encoder_decoder2.predict(nn_velo,nn_velo_nth_input, 59))\n",
    "        total_loss += ((torch.cumsum(torch.cat((init_pos, deltas)), dim=0) - nth_output_centered) ** 2).mean()\n",
    "\n",
    "    valid_loss = total_loss / val_dataset.__len__()\n",
    "    \n",
    "    print(\"Final validation loss is: \" + valid_loss + \" for \" + city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8e6b2-c37e-4732-907d-57b46e3c59b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c26e8-fbdb-459b-b404-d04c62453219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4801506-77ab-483a-9d12-0568412cfcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b0372-8566-43da-b20e-bd1b3c7a434c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be9f4c-8e08-46b4-b37c-595b3d4b4713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd9fd7-c519-4158-b22e-c6caa84b31c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca425d32-1829-4bc3-b906-e167fc495c32",
   "metadata": {},
   "source": [
    "### Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa45f5-9995-4767-83a4-41ae9ffa1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pos.eval()\n",
    "nn_velo.eval()\n",
    "\n",
    "all_preds = []\n",
    "for city in cities:\n",
    "    test_dataset = ArgoverseDataset(city=city, split='test')\n",
    "    rows = []\n",
    "    model_pos = pickle.load(open('./models/seq2seq_lstm_' + str(self.num_layers) + '_' + city, 'rb'))\n",
    "    model_velo = pickle.load(open('./models/seq2seq_lstm_' + str(self.num_layers) + '_' + city, 'rb'))\n",
    "    for n in range(test_dataset.__len__()):\n",
    "        if n % 1_000 == 0 and n > 0: \n",
    "            print(str(n) + ' predictions for ' + str(city) + ' completed.')\n",
    "        nn_pos_nth_input, nn_velo_nth_input, center_input = test_dataset.__getitem__(n)\n",
    "        init_pos = torch.Tensor(model_pos.predict(nn_pos_nth_input, 1))\n",
    "        deltas = torch.Tensor(model_pos.predict(nn_velo_nth_input, 59))\n",
    "        pred = (torch.cumsum(torch.cat((init_pos, deltas)), dim=0).flatten() + center_input).numpy()\n",
    "        rows.append(pred)\n",
    "    ids = np.array([str(i) + '_' + city for i in range(len(rows))])\n",
    "    cols = np.array(['v' + str(i) for i in range(120)])\n",
    "    predictions = pd.DataFrame(rows, columns=cols)\n",
    "    predictions.insert(0, 'ID', ids)\n",
    "    all_preds.append(predictions)\n",
    "all_predictions = pd.concat(all_preds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cb88e-5a41-46ee-81fb-d5ed7b79c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.to_csv('two_lstm_enc_dec_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e0ca7-6c3f-4163-be3d-19f7f025bcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cab5f-319c-4e03-8c77-c17d521e414c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
